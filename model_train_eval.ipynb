{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Import libraries",
   "id": "84f43592917362da"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-07T21:46:50.521481Z",
     "start_time": "2025-11-07T21:46:50.515901Z"
    }
   },
   "source": [
    "import itertools\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "import wandb\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json"
   ],
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. Configuration",
   "id": "55b75caa26e68e22"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1.1 Init",
   "id": "bf9dbff12e70ee96"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T21:27:39.299182Z",
     "start_time": "2025-11-07T21:27:39.287510Z"
    }
   },
   "cell_type": "code",
   "source": [
    "WANDB_PROJECT_NAME = \"zneus-project-1\"\n",
    "dataset_used = \"full_features\"\n",
    "path = f\"data/transformed/{dataset_used}\" #path of used dataset\n",
    "IS_WANDB = True\n",
    "run_id = 1\n",
    "\n",
    "#using seed for consistent experiments\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "#if cuda available, use it \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device used: {device}\")\n",
    "\n",
    "#model parameters\n",
    "EPOCH = 50\n",
    "BATCH_SIZE = 128\n",
    "LR = 0.001\n",
    "    \n",
    "#transformer for inverse transforms\n",
    "target_transformer = joblib.load(f\"{path}/house_value_scaler.pkl\")"
   ],
   "id": "4891b92ec6afd5ed",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used: cuda\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1.1.1 Wandb init",
   "id": "34ef3161023d802d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T20:54:34.629172Z",
     "start_time": "2025-11-07T20:54:34.623632Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def init_wandb(name=f\"{dataset_used}_{run_id}\", config_dict=None):\n",
    "    if IS_WANDB:\n",
    "        default_config = {\n",
    "            \"batch_size\": BATCH_SIZE,\n",
    "            \"epoch\": EPOCH,\n",
    "            \"lr\": LR,\n",
    "            \"loss_fn\": \"MSELoss\",\n",
    "            \"dataset_path\": path,\n",
    "            \"activation\": \"LeakyReLU\",\n",
    "            \"optimizer\": \"Adam\",\n",
    "            \"weight_decay\": 0.0\n",
    "        }\n",
    "\n",
    "        #use dict from tuning\n",
    "        if config_dict is not None:\n",
    "            default_config.update(config_dict)\n",
    "            \n",
    "        wandb.init(\n",
    "            project=f\"{WANDB_PROJECT_NAME}\",\n",
    "            name=name,\n",
    "            config=default_config\n",
    "        )"
   ],
   "id": "49251e27c43d1411",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1.2 Model parameters",
   "id": "8a73f3ec02972e89"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T20:29:32.853984Z",
     "start_time": "2025-11-07T20:29:32.849382Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class CSVDataset(Dataset):\n",
    "    def __init__(self, path: str):\n",
    "        df = pd.read_csv(path)\n",
    "        self.X = torch.tensor(df.iloc[:, :-1].values, dtype=torch.float32)\n",
    "        self.y = torch.tensor(df.iloc[:, -1].values, dtype=torch.float32).view(-1, 1) # last element is predicted value\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "    \n",
    "#load datasets from disk\n",
    "def get_datasets(path: str) -> List[CSVDataset]:\n",
    "    return [\n",
    "        CSVDataset(f\"{path}/train.csv\"),\n",
    "        CSVDataset(f\"{path}/test.csv\"),\n",
    "        CSVDataset(f\"{path}/eval.csv\")\n",
    "    ]"
   ],
   "id": "2594784ce6dfd858",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 1.3 Model class - variants\n",
    "#### 1.3.1 Base"
   ],
   "id": "302800e270f0ce52"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T20:27:55.389896Z",
     "start_time": "2025-11-07T20:27:55.384910Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size: int):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_size, 128),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ],
   "id": "b07488c7affe1fe4",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 1.3.2 Dropout ",
   "id": "94e94c4f4d3a980"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T20:28:12.883299Z",
     "start_time": "2025-11-07T20:28:12.878505Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SimpleNN_dropout(nn.Module):\n",
    "    def __init__(self, input_size: int):\n",
    "        super(SimpleNN_dropout, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_size, 128),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ],
   "id": "b5a1126448669c05",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 1.3.3 Batch Normalization",
   "id": "1748f8c352d77a02"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T20:28:31.552309Z",
     "start_time": "2025-11-07T20:28:31.547634Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SimpleNN_batch_norm(nn.Module):\n",
    "    def __init__(self, input_size: int):\n",
    "        super(SimpleNN_batch_norm, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_size, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.LeakyReLU(0.3),\n",
    "\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.LeakyReLU(0.1),\n",
    "\n",
    "            nn.Linear(64, 32),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.LeakyReLU(0.1),\n",
    "\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ],
   "id": "fb254eb5a324f22f",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 1.3.4 Skip connections",
   "id": "95b5870da003729a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T20:28:51.421683Z",
     "start_time": "2025-11-07T20:28:51.409938Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SimpleNN_Res(nn.Module): #skip connections\n",
    "    def __init__(self, input_size: int):\n",
    "        super(SimpleNN_Res, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.act1 = nn.LeakyReLU(0.3)\n",
    "\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.act2 = nn.LeakyReLU(0.1)\n",
    "\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.act3 = nn.LeakyReLU(0.1)\n",
    "\n",
    "        self.out = nn.Linear(32, 1)\n",
    "\n",
    "        #projection for skip connections\n",
    "        self.skip_proj = nn.Linear(input_size, 64)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #first layer\n",
    "        x1 = self.act1(self.fc1(x))\n",
    "\n",
    "        #skip connection: input x + projection to 64\n",
    "        skip = self.skip_proj(x)\n",
    "        x2 = self.act2(self.fc2(x1) + skip) #residual connection\n",
    "\n",
    "        #next layer\n",
    "        x3 = self.act3(self.fc3(x2))\n",
    "\n",
    "        out = self.out(x3)\n",
    "        return out"
   ],
   "id": "ecd5d7b4fa868617",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 1.3.5 Bottleneck layers",
   "id": "900f4d802aaa2b9a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T20:29:10.254430Z",
     "start_time": "2025-11-07T20:29:10.249092Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SimpleNN_Bottleneck(nn.Module):\n",
    "    def __init__(self, input_size: int, bottleneck_size: int = 16):\n",
    "        super(SimpleNN_Bottleneck, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.act1 = nn.LeakyReLU(0.3)\n",
    "\n",
    "        #bottleneck layer\n",
    "        self.fc2 = nn.Linear(128, bottleneck_size)\n",
    "        self.act2 = nn.LeakyReLU(0.1)\n",
    "\n",
    "        #output layer\n",
    "        self.fc3 = nn.Linear(bottleneck_size, 32)\n",
    "        self.act3 = nn.LeakyReLU(0.1)\n",
    "\n",
    "        self.out = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.act1(self.fc1(x))\n",
    "        x2 = self.act2(self.fc2(x1))\n",
    "        x3 = self.act3(self.fc3(x2))\n",
    "        out = self.out(x3)\n",
    "        return out"
   ],
   "id": "8ea86ed28a8c6537",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1.4 Load data",
   "id": "8dec10b4071f8b92"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T21:12:10.040149Z",
     "start_time": "2025-11-07T21:12:09.988610Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#load datasets and create loss function\n",
    "train_df, test_df, eval_df = get_datasets(path)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "\n",
    "def create_loaders(batch_size):\n",
    "    #divide datasets into batches\n",
    "    train_loader = DataLoader(train_df, batch_size=batch_size, shuffle=True, worker_init_fn=lambda worker_id: np.random.seed(RANDOM_SEED + worker_id))\n",
    "    test_loader = DataLoader(test_df, batch_size=batch_size, shuffle=True, worker_init_fn=lambda worker_id: np.random.seed(RANDOM_SEED + worker_id))\n",
    "    eval_loader = DataLoader(eval_df, batch_size=batch_size, shuffle=True, worker_init_fn=lambda worker_id: np.random.seed(RANDOM_SEED + worker_id))\n",
    "    \n",
    "    return train_loader, test_loader, eval_loader\n",
    "\n",
    "train_loader, test_loader, eval_loader = create_loaders(BATCH_SIZE) #for base experiment"
   ],
   "id": "23d719ced30b9c4c",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1.5 Inverse transform init",
   "id": "3b3c43a7865ca8e5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T20:34:51.502831Z",
     "start_time": "2025-11-07T20:34:51.498669Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#inverse transform the input for original values\n",
    "def get_inverse_transformed(y, y_transformer=None):\n",
    "    if y_transformer is not None:\n",
    "        y = y.cpu().numpy().reshape(-1, 1)\n",
    "        y = y_transformer.inverse_transform(y)\n",
    "        return torch.tensor(y, dtype=torch.float32, device=device)\n",
    "    return y"
   ],
   "id": "bbb53af544ec3414",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1.6 Evaluate model",
   "id": "4c22a23a9dfd4da0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T20:35:46.223384Z",
     "start_time": "2025-11-07T20:35:46.211820Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate(eloader: DataLoader, model, loss_fn, y_transformer=None, is_test=False):\n",
    "    model.eval()\n",
    "    total_test_loss = 0\n",
    "    total_test_loss_original = 0\n",
    "    num_of_batches = len(eloader)\n",
    "\n",
    "    mse_losses, rmse_losses = [], [] #for test only\n",
    "\n",
    "    with torch.no_grad():\n",
    "        if is_test:\n",
    "            print(\"\\n====TESTING====\")\n",
    "\n",
    "        for index, (X, y) in enumerate(eloader):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            y_pred = model(X)\n",
    "\n",
    "            loss_transformed = loss_fn(y_pred, y).item()\n",
    "            mse_losses.append(loss_transformed)\n",
    "            total_test_loss += loss_transformed\n",
    "\n",
    "            y_pred = get_inverse_transformed(y_pred, y_transformer)\n",
    "            y = get_inverse_transformed(y, y_transformer)\n",
    "\n",
    "            loss_original = loss_fn(y_pred, y).item()\n",
    "            total_test_loss_original += loss_original\n",
    "            if is_test:\n",
    "                rmse = loss_original ** 0.5\n",
    "                rmse_losses.append(rmse)\n",
    "\n",
    "                print(f\"Test eval: Batch {index + 1:03d}: MSE={loss_transformed:.4f}, RMSE={rmse:.4f}\")\n",
    "\n",
    "    return total_test_loss/num_of_batches, total_test_loss_original/num_of_batches, mse_losses, rmse_losses, num_of_batches"
   ],
   "id": "e1e1fe9c254c1799",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1.7 Train model",
   "id": "736af6917b68a12d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T21:23:55.496851Z",
     "start_time": "2025-11-07T21:23:55.489561Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train(train: CSVDataset, train_loader: DataLoader, eval_loader: DataLoader, loss_fn, transformer=None, model=None, optimizer=None, tuning=False) -> (any, List[float], List[float]):\n",
    "    model = model if model else SimpleNN_Bottleneck(train.X.shape[1]).to(device) #in tuning we pass the model, else its base\n",
    "\n",
    "    optimizer = optimizer if optimizer else optim.Adam(model.parameters(), lr=LR) #same with optimizer\n",
    "    train_mse, eval_mse = [], []\n",
    "    train_rmse, eval_rmse = [], []\n",
    "\n",
    "    if not tuning: print(\"\\n====TRAINING====\")\n",
    "    for epoch in range(EPOCH):\n",
    "        model.train()\n",
    "        total_train_mse = 0\n",
    "        total_train_rmse = 0\n",
    "\n",
    "        for X, y in train_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            #predict y\n",
    "            y_pred = model(X)\n",
    "\n",
    "            #calculate loss\n",
    "            loss = loss_fn(y_pred, y)\n",
    "            total_train_mse += loss.item()\n",
    "\n",
    "            #backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            #calculate non-normalized loss, for logging\n",
    "            with torch.no_grad():\n",
    "                #inverse transform predicted and true y values\n",
    "                y_orig = get_inverse_transformed(y.detach(), transformer)\n",
    "                y_pred_orig = get_inverse_transformed(y_pred.detach(), transformer)\n",
    "\n",
    "                #calculate mse and rmse from results\n",
    "                mse = loss_fn(y_pred_orig, y_orig).item()\n",
    "                rmse = mse ** 0.5\n",
    "\n",
    "                total_train_rmse += rmse\n",
    "\n",
    "        #average train mse/rmse per epoch\n",
    "        avg_train_mse = total_train_mse / len(train_loader)\n",
    "        avg_train_rmse = total_train_rmse / len(train_loader)\n",
    "\n",
    "        #test on eval set\n",
    "        eval_mse_e, eval_mse_original, _, _, _ = evaluate(eval_loader, model, loss_fn, transformer)\n",
    "        eval_rmse_e = eval_mse_original ** 0.5\n",
    "\n",
    "        #add to arrays\n",
    "        train_mse.append(avg_train_mse)\n",
    "        eval_mse.append(eval_mse_e)\n",
    "        train_rmse.append(avg_train_rmse)\n",
    "        eval_rmse.append(eval_rmse_e)\n",
    "\n",
    "        if not tuning:\n",
    "            print(f\"Epoch {epoch+1:03d}: train RMSE={avg_train_rmse:.4f}, eval RMSE={eval_rmse_e:.4f}\")\n",
    "    \n",
    "    return model, train_mse, eval_mse, train_rmse, eval_rmse"
   ],
   "id": "d26f03e93bdc5b8b",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1.8 Plotting the results locally",
   "id": "9acbda112044895d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T21:26:59.843683Z",
     "start_time": "2025-11-07T21:26:59.835732Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def plot_res(tr_mse, ev_mse, tr_rmse, ev_rmse, te_mse_losses, te_rmse_losses, test_batches):\n",
    "    #plot mse losses\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(range(1, len(tr_mse) + 1), tr_mse, label=\"Training MSE\", linewidth=2)\n",
    "    plt.plot(range(1, len(ev_mse) + 1), ev_mse, label=\"Evaluation MSE\", linewidth=2)\n",
    "    plt.title(\"Training, Evaluation MSE Over Epochs\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"MSE\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    #plot rmse - real losses in €\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(range(1, len(tr_rmse) + 1), tr_rmse, label=\"Training RMSE\", linewidth=2)\n",
    "    plt.plot(range(1, len(ev_rmse) + 1), ev_rmse, label=\"Evaluation RMSE\", linewidth=2)\n",
    "    plt.title(\"Training, Evaluation RMSE Over Epochs\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"RMSE (€)\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    #test plots - mse\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(range(1, test_batches + 1), te_mse_losses, label=\"Test MSE\", linewidth=2)\n",
    "    plt.title(\"Test MSE Over Batches\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"MSE\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    #test plots - rmse\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(range(1, test_batches + 1), te_rmse_losses, label=\"Test RMSE\", linewidth=2)\n",
    "    plt.title(\"Test RMSE Over Batches\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"RMSE (€)\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "id": "879d703c7a8d02cd",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1.9 Train the model and log the results into WandB and plot locally if allowed in init",
   "id": "bfee22b44dbac1a4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T21:44:02.585430Z",
     "start_time": "2025-11-07T21:44:02.577599Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def run_experiment(model=None, optimizer=None, train_loader=None, test_loader=None, eval_loader=None, tuning=False, tuning_param=None):\n",
    "    #start wandb run\n",
    "    if tuning:\n",
    "        init_wandb(tuning_param[0], tuning_param[1])\n",
    "    else:\n",
    "        init_wandb()\n",
    "    \n",
    "    #train \n",
    "    model, tr_mse, ev_mse, tr_rmse, ev_rmse = train(train_df, train_loader, eval_loader, loss_fn, target_transformer, model, optimizer, tuning)\n",
    "    \n",
    "    #evaluate on train dataset, seen data\n",
    "    train_mse, train_mse_original, _, _, _ = evaluate(train_loader, model, loss_fn, target_transformer, is_test=True)\n",
    "    train_eval_rmse = train_mse_original ** 0.5\n",
    "    \n",
    "    #evaluate test dataset, unseen data\n",
    "    test_mse, test_mse_original, te_mse_losses, te_rmse_losses, test_batches = evaluate(test_loader, model, loss_fn, target_transformer, is_test=True)\n",
    "    te_rmse = test_mse_original ** 0.5\n",
    "    \n",
    "    #log results\n",
    "    if IS_WANDB:\n",
    "        for epoch, (mse_t, mse_e, rmse_t, rmse_e) in enumerate(zip(tr_mse, ev_mse, tr_rmse, ev_rmse), 1):\n",
    "            wandb.log({\n",
    "                \"epoch\": epoch,\n",
    "                \"train_MSE\": mse_t,\n",
    "                \"eval_MSE\": mse_e,\n",
    "                \"train_RMSE\": rmse_t,\n",
    "                \"eval_RMSE\": rmse_e,\n",
    "            })\n",
    "    \n",
    "    \n",
    "        for batch in range(1, test_batches+1):\n",
    "            wandb.log({\n",
    "                \"batch\": batch,\n",
    "                \"test_MSE\": te_mse_losses[batch-1],\n",
    "                \"test_RMSE\": te_rmse_losses[batch-1]\n",
    "            })\n",
    "    \n",
    "        wandb.finish()\n",
    "    \n",
    "    \n",
    "    print(f\"Train RMSE: {train_eval_rmse:.4f}, Test RMSE: {te_rmse:.4f}\")\n",
    "    \n",
    "    if not tuning: #during tuning we dont plot graphs\n",
    "        plot_res(tr_mse, ev_mse, tr_rmse, ev_rmse, te_mse_losses, te_rmse_losses, test_batches)\n",
    "        \n",
    "    return te_rmse "
   ],
   "id": "953f92414cf0127a",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T21:26:24.709012Z",
     "start_time": "2025-11-07T21:25:50.528633Z"
    }
   },
   "cell_type": "code",
   "source": [
    "run_experiment(train_loader=train_loader, test_loader=test_loader, eval_loader=eval_loader,tuning=False) #run sample experiment\n",
    "run_id += 1"
   ],
   "id": "922ade0cf2cb8b23",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">full_features_1</strong> at: <a href='https://wandb.ai/xhanushchak-slovensk-technick-univerzita-v-bratislave/zneus-project-1/runs/i7dy7v2z' target=\"_blank\">https://wandb.ai/xhanushchak-slovensk-technick-univerzita-v-bratislave/zneus-project-1/runs/i7dy7v2z</a><br> View project at: <a href='https://wandb.ai/xhanushchak-slovensk-technick-univerzita-v-bratislave/zneus-project-1' target=\"_blank\">https://wandb.ai/xhanushchak-slovensk-technick-univerzita-v-bratislave/zneus-project-1</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251107_222436-i7dy7v2z\\logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>C:\\zeus\\projekt1\\wandb\\run-20251107_222550-pnsym64m</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/xhanushchak-slovensk-technick-univerzita-v-bratislave/zneus-project-1/runs/pnsym64m' target=\"_blank\">full_features_1</a></strong> to <a href='https://wandb.ai/xhanushchak-slovensk-technick-univerzita-v-bratislave/zneus-project-1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/xhanushchak-slovensk-technick-univerzita-v-bratislave/zneus-project-1' target=\"_blank\">https://wandb.ai/xhanushchak-slovensk-technick-univerzita-v-bratislave/zneus-project-1</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/xhanushchak-slovensk-technick-univerzita-v-bratislave/zneus-project-1/runs/pnsym64m' target=\"_blank\">https://wandb.ai/xhanushchak-slovensk-technick-univerzita-v-bratislave/zneus-project-1/runs/pnsym64m</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====TRAINING====\n",
      "Epoch 001: train RMSE=90925.1669, eval RMSE=63333.1445\n",
      "Epoch 002: train RMSE=64117.8714, eval RMSE=61763.8810\n",
      "Epoch 003: train RMSE=62879.3062, eval RMSE=61326.7758\n",
      "Epoch 004: train RMSE=61942.6413, eval RMSE=59237.4521\n",
      "Epoch 005: train RMSE=61140.1828, eval RMSE=60030.9202\n",
      "Epoch 006: train RMSE=60453.3685, eval RMSE=58359.0641\n",
      "Epoch 007: train RMSE=59444.2439, eval RMSE=58703.5500\n",
      "Epoch 008: train RMSE=59036.7206, eval RMSE=56227.6006\n",
      "Epoch 009: train RMSE=58365.9409, eval RMSE=57002.5790\n",
      "Epoch 010: train RMSE=57728.3233, eval RMSE=55678.9050\n",
      "Epoch 011: train RMSE=57403.1128, eval RMSE=55601.8768\n",
      "Epoch 012: train RMSE=57119.1338, eval RMSE=55635.3171\n",
      "Epoch 013: train RMSE=56372.6768, eval RMSE=55166.3023\n",
      "Epoch 014: train RMSE=56225.9718, eval RMSE=54752.0996\n",
      "Epoch 015: train RMSE=56208.0232, eval RMSE=53974.5781\n",
      "Epoch 016: train RMSE=55604.3005, eval RMSE=54206.1032\n",
      "Epoch 017: train RMSE=55437.2319, eval RMSE=55097.9292\n",
      "Epoch 018: train RMSE=55211.9810, eval RMSE=53776.4555\n",
      "Epoch 019: train RMSE=55019.1817, eval RMSE=55749.6428\n",
      "Epoch 020: train RMSE=55179.3363, eval RMSE=53778.7911\n",
      "Epoch 021: train RMSE=54727.3986, eval RMSE=53444.2799\n",
      "Epoch 022: train RMSE=54937.2021, eval RMSE=54079.6920\n",
      "Epoch 023: train RMSE=54552.1105, eval RMSE=54463.2723\n",
      "Epoch 024: train RMSE=54507.1963, eval RMSE=53648.4870\n",
      "Epoch 025: train RMSE=54581.8052, eval RMSE=53926.6664\n",
      "Epoch 026: train RMSE=54422.4101, eval RMSE=54338.8752\n",
      "Epoch 027: train RMSE=54548.8600, eval RMSE=53108.9835\n",
      "Epoch 028: train RMSE=54258.0370, eval RMSE=52871.5650\n",
      "Epoch 029: train RMSE=54275.1048, eval RMSE=54785.5478\n",
      "Epoch 030: train RMSE=54019.0754, eval RMSE=54094.8251\n",
      "Epoch 031: train RMSE=54077.6855, eval RMSE=53012.3396\n",
      "Epoch 032: train RMSE=53970.8022, eval RMSE=53178.5109\n",
      "Epoch 033: train RMSE=53842.8737, eval RMSE=53929.8873\n",
      "Epoch 034: train RMSE=54030.3082, eval RMSE=53311.6783\n",
      "Epoch 035: train RMSE=54057.8147, eval RMSE=53944.5536\n",
      "Epoch 036: train RMSE=53800.1018, eval RMSE=53543.3960\n",
      "Epoch 037: train RMSE=53787.1995, eval RMSE=53197.4664\n",
      "Epoch 038: train RMSE=53686.6998, eval RMSE=53691.1772\n",
      "Epoch 039: train RMSE=53589.2173, eval RMSE=52802.4828\n",
      "Epoch 040: train RMSE=53374.0911, eval RMSE=53062.1011\n",
      "Epoch 041: train RMSE=53513.9204, eval RMSE=52745.1897\n",
      "Epoch 042: train RMSE=53287.4938, eval RMSE=53451.7321\n",
      "Epoch 043: train RMSE=53170.3634, eval RMSE=52455.4882\n",
      "Epoch 044: train RMSE=53507.1231, eval RMSE=53112.0384\n",
      "Epoch 045: train RMSE=53107.4648, eval RMSE=53602.0779\n",
      "Epoch 046: train RMSE=53013.4907, eval RMSE=53649.4620\n",
      "Epoch 047: train RMSE=52965.9605, eval RMSE=53021.2468\n",
      "Epoch 048: train RMSE=53033.1420, eval RMSE=52697.3234\n",
      "Epoch 049: train RMSE=52913.3200, eval RMSE=56479.5905\n",
      "Epoch 050: train RMSE=52931.5900, eval RMSE=53985.0498\n",
      "\n",
      "====TESTING====\n",
      "Test eval: Batch 001: MSE=0.0115, RMSE=52019.3908\n",
      "Test eval: Batch 002: MSE=0.0133, RMSE=56008.1046\n",
      "Test eval: Batch 003: MSE=0.0130, RMSE=55268.9702\n",
      "Test eval: Batch 004: MSE=0.0135, RMSE=56401.2278\n",
      "Test eval: Batch 005: MSE=0.0140, RMSE=57472.8018\n",
      "Test eval: Batch 006: MSE=0.0152, RMSE=59842.7892\n",
      "Test eval: Batch 007: MSE=0.0101, RMSE=48761.8316\n",
      "Test eval: Batch 008: MSE=0.0131, RMSE=55518.8703\n",
      "Test eval: Batch 009: MSE=0.0106, RMSE=49874.6281\n",
      "Test eval: Batch 010: MSE=0.0132, RMSE=55757.9776\n",
      "Test eval: Batch 011: MSE=0.0111, RMSE=51192.2194\n",
      "Test eval: Batch 012: MSE=0.0270, RMSE=79698.6324\n",
      "Test eval: Batch 013: MSE=0.0140, RMSE=57424.4859\n",
      "Test eval: Batch 014: MSE=0.0145, RMSE=58319.4579\n",
      "Test eval: Batch 015: MSE=0.0110, RMSE=50802.7539\n",
      "Test eval: Batch 016: MSE=0.0189, RMSE=66739.9951\n",
      "Test eval: Batch 017: MSE=0.0145, RMSE=58476.4278\n",
      "Test eval: Batch 018: MSE=0.0084, RMSE=44393.9599\n",
      "Test eval: Batch 019: MSE=0.0133, RMSE=55888.8405\n",
      "Test eval: Batch 020: MSE=0.0146, RMSE=58638.7842\n",
      "Test eval: Batch 021: MSE=0.0099, RMSE=48178.1733\n",
      "Test eval: Batch 022: MSE=0.0134, RMSE=56081.8602\n",
      "Test eval: Batch 023: MSE=0.0123, RMSE=53680.4387\n",
      "Test eval: Batch 024: MSE=0.0153, RMSE=59964.4951\n",
      "Test eval: Batch 025: MSE=0.0130, RMSE=55292.4166\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>eval_MSE</td><td>█▇▇▅▆▅▃▄▃▃▃▂▂▂▂▂▁▂▂▂▂▁▁▂▂▁▂▁▂▂▂▁▁▁▁▁▂▁▁▂</td></tr><tr><td>eval_RMSE</td><td>█▇▇▅▆▅▃▄▃▃▃▂▂▂▃▃▂▂▂▂▂▂▂▂▁▂▂▂▂▁▁▁▁▂▁▂▂▁▁▂</td></tr><tr><td>test_MSE</td><td>▂▃▃▃▃▄▂▃▂▃▂█▃▃▂▅▃▁▃▃▂▃▂▄▃</td></tr><tr><td>test_RMSE</td><td>▃▃▃▃▄▄▂▃▂▃▂█▄▄▂▅▄▁▃▄▂▃▃▄▃</td></tr><tr><td>train_MSE</td><td>█▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_RMSE</td><td>█▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch</td><td>25</td></tr><tr><td>epoch</td><td>50</td></tr><tr><td>eval_MSE</td><td>0.01239</td></tr><tr><td>eval_RMSE</td><td>53985.04981</td></tr><tr><td>test_MSE</td><td>0.013</td></tr><tr><td>test_RMSE</td><td>55292.41655</td></tr><tr><td>train_MSE</td><td>0.01206</td></tr><tr><td>train_RMSE</td><td>52931.59003</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">full_features_1</strong> at: <a href='https://wandb.ai/xhanushchak-slovensk-technick-univerzita-v-bratislave/zneus-project-1/runs/pnsym64m' target=\"_blank\">https://wandb.ai/xhanushchak-slovensk-technick-univerzita-v-bratislave/zneus-project-1/runs/pnsym64m</a><br> View project at: <a href='https://wandb.ai/xhanushchak-slovensk-technick-univerzita-v-bratislave/zneus-project-1' target=\"_blank\">https://wandb.ai/xhanushchak-slovensk-technick-univerzita-v-bratislave/zneus-project-1</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251107_222550-pnsym64m\\logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 56454.9832\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "plot_res() takes 6 positional arguments but 7 were given",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mTypeError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[36]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[43mrun_experiment\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_loader\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtest_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meval_loader\u001B[49m\u001B[43m=\u001B[49m\u001B[43meval_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43mtuning\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[31]\u001B[39m\u001B[32m, line 39\u001B[39m, in \u001B[36mrun_experiment\u001B[39m\u001B[34m(model, optimizer, train_loader, test_loader, eval_loader, tuning, tuning_param)\u001B[39m\n\u001B[32m     36\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mTest RMSE: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mte_rmse\u001B[38;5;132;01m:\u001B[39;00m\u001B[33m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m     38\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m tuning: \u001B[38;5;66;03m#during tuning we dont plot graphs\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m39\u001B[39m     \u001B[43mplot_res\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtr_mse\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mev_mse\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtr_rmse\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mev_rmse\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mte_mse_losses\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mte_rmse_losses\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_batches\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mTypeError\u001B[39m: plot_res() takes 6 positional arguments but 7 were given"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1.10 Hyperparameter tuning",
   "id": "e692b0f425909a22"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T21:46:41.081182Z",
     "start_time": "2025-11-07T21:46:41.067222Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def hyperparameter_tuning(train_set: CSVDataset):\n",
    "    run_id = 0\n",
    "    best_rmse = float(\"inf\")\n",
    "    best_config = None\n",
    "    \n",
    "    activation_options = [nn.ReLU, lambda: nn.LeakyReLU(0.1)]\n",
    "    optimizer_options = ['Adam', 'SGD']\n",
    "    learning_rates = {\n",
    "        'Adam': [1e-4, 3e-4, 1e-3],\n",
    "        'SGD': [1e-2, 3e-3, 1e-3]\n",
    "    }\n",
    "    batch_sizes = [64, 128]\n",
    "    weight_decays = [0, 1e-4]\n",
    "\n",
    "    param_grid = list(itertools.product(\n",
    "        activation_options,\n",
    "        optimizer_options,\n",
    "        batch_sizes,\n",
    "        weight_decays\n",
    "    ))\n",
    "\n",
    "    total_runs = sum(len(learning_rates[o]) for _, o, _, _ in param_grid)\n",
    "    print(f\"Starting hyperparameter tuning: {total_runs} total runs\\n\")\n",
    "\n",
    "    #for effectivity, lets init all needed data loaders needed for experiments\n",
    "    loaders = []\n",
    "    for b in batch_sizes:\n",
    "        train_loader, test_loader, eval_loader = create_loaders(b)\n",
    "        loaders.append([train_loader, test_loader, eval_loader]) #index of b in batch_sizes\n",
    "\n",
    "    for act_fn, opt_name, batch, wd in param_grid:\n",
    "        loader_idx = batch_sizes.index(batch)\n",
    "        for lr in learning_rates[opt_name]:\n",
    "            activation = act_fn()\n",
    "            model = SimpleNN_Res(train_set.X.shape[1]).to(device)\n",
    "            model.act1 = activation\n",
    "            model.act2 = activation\n",
    "            model.act3 = activation\n",
    "\n",
    "            #optimizer\n",
    "            if opt_name == 'Adam':\n",
    "                optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "            elif opt_name == 'SGD':\n",
    "                optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=wd)\n",
    "            \n",
    "            exp_name = f\"{dataset_used}_parameter_tuning_{run_id}\"\n",
    "            config_dict = {\n",
    "                \"activation\": act_fn.__name__ if hasattr(act_fn, \"__name__\") else \"LeakyReLU(0.1)\",\n",
    "                \"batch_size\": batch,\n",
    "                \"epoch\": EPOCH,\n",
    "                \"lr\": lr,\n",
    "                \"loss_fn\": \"MSELoss\",\n",
    "                \"dataset_path\": path,\n",
    "                \"optimizer\": opt_name,\n",
    "                \"weight_decay\": wd\n",
    "            }\n",
    "            \n",
    "            print(f\"[{run_id+1}/{total_runs}] Starting: \"\n",
    "                  f\"{config_dict['optimizer']} | act={config_dict['activation']} | \"\n",
    "                  f\"lr={lr} | wd={wd} | batch={batch}\")\n",
    "            \n",
    "            \n",
    "            test_rmse = run_experiment(model=model, optimizer=optimizer, train_loader=loaders[loader_idx][0], test_loader=loaders[loader_idx][1], eval_loader=loaders[loader_idx][2], tuning=True, tuning_param=[exp_name,config_dict])\n",
    "            \n",
    "            if test_rmse < best_rmse:\n",
    "                best_rmse = test_rmse\n",
    "                best_config = config_dict\n",
    "                print(f\"New best RMSE: {best_rmse:.4f} with config {best_config}\")\n",
    "                \n",
    "            run_id += 1\n",
    "    \n",
    "    if best_config is not None:\n",
    "        with open(\"best_config.json\", \"w\") as f:\n",
    "            json.dump({\"best_rmse\": best_rmse, \"config\": best_config}, f, indent=4)\n",
    "        print(f\"\\nBest configuration saved to best_config.json:\")\n",
    "        print(json.dumps(best_config, indent=4))\n",
    "    else:\n",
    "        print(\"No valid configuration found!\")\n"
   ],
   "id": "e2eb6233c100917c",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "hyperparameter_tuning(train_df) #start hyperparameter tuning",
   "id": "d8f7846031f25ed5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
